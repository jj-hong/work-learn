###### 对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择及优化则是在逐步接近这个上限;
###### 在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关;
###### 两类数据：结构化数据和非结构化数据
###### 两类特征：数值型特征和类别型特征
---

1. 特征归一化的目的、常用方法、适用场景？
> Normalization

> 为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。

> 最常用的方法有两种：线性归一化（Min-Max Scaling）和零均值归一化（Z-Score Normalization）。

> 在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型，但对于决策树模型则并不适用。

2. 类别型特征的处理方法？
> Categorical Feature

> 序号编码（Ordinal Encoding）、独热编码（One-hot Encoding）、二进制编码（Binary Encoding）

> 序号编码通常用于处理类别间具有大小关系的数据；独热编码通常用于处理类别间不具有大小关系的特征；二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后
将类别ID对应的二进制编码作为结果。

3. 什么是组合特征、高维组合特征的处理
> 为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征

> 特征组合的寻找方法？
>> 决策树、梯度提升决策树
