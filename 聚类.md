*非监督学习主要包含两大类学习方法：数据聚类和特征变量关联。其中，聚类算法往往是通过多次迭代来找到数据的最优分割，而特征变量关联则是利用各种相关性分析方法来找到变量之间的关系。*

## 1. K-means
> 代价函数：误差平方和

#### K-means 算法的改进
*初始聚类中心、合适的K值*
> k-means++ 改善初始聚类中心

> isodata算法确当合适K值
#### K-means 与 EM算法的关系

#### K-means算法的优缺点与调优方法
*受初值和离群点的影响每次的结果不稳定、结果通常不是全局最优而是局部最优解、无法很好地解决数据簇分布差别比较大的情况（比如一类是另一类样本数量的100倍）、不太适用于离散分类等。但是瑕不掩、瑜，K均值聚类的优点也是很明显和突出的，主要体现在：对于大数据集，K均值聚类算法相对是可伸缩和高效的，它的计算复杂度是O(NKt)接近于线性，其中N是数据对象的数目，K是聚类的簇数，t是迭代的轮数。尽管算法经常以局部最优结束，但一般情况下达到的局部最优已经可以满足聚类的需求*

>调优方法：

>1. 数据归一化和离群点处理

>2. 合理选择K值

>3. 采用核函数

## 2. 高斯混合模型（GMM）
*高斯混合模型（Gaussian Mixed Model，GMM）也是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代计算。高斯混合模型假设每个簇的数据都是符合高斯分布（又叫正态分布）的，当前数据呈现的分布就是各个簇的高斯分布叠加在一起的结果*

> 是一个生成式模型
#### 模型的核心思想与计算步骤

## 3. 聚类算法评估
>估计聚类趋势

>判定数据簇数

>测定聚类质量
